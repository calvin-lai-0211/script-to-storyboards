#!/usr/bin/env python3
"""
RunningHub API Jimeng Text-to-Image implementation.
Provides text-to-image generation using RunningHub API's Jimeng model.
"""

import time
import requests
import json
import os
from datetime import datetime
from typing import Optional, Dict, Any, Union, List, Callable
from PIL import Image
import logging
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import random

from utils.config import RUNNINGHUB_API_CONFIG

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RunningHubConcurrencyManager:
    """RunningHubå¹¶å‘ç®¡ç†å™¨ - æå…¶ä¿å®ˆçš„å¹¶å‘æ§åˆ¶ï¼Œé¿å…TASK_QUEUE_MAXEDé”™è¯¯"""
    
    def __init__(self, max_concurrent: int = 3, conservative_threshold: int = 1):
        # æ³¨æ„ï¼šconservative_thresholdè®¾ä¸º1ä»¥é¿å…æœåŠ¡å™¨é˜Ÿåˆ—é™åˆ¶
        self.max_concurrent = max_concurrent
        self.conservative_threshold = max(1, conservative_threshold)  # æœ€å°ä¸º1ï¼Œæå…¶ä¿å®ˆ
        self.submitted_tasks = 0  # å·²æäº¤åˆ°æœåŠ¡å™¨çš„ä»»åŠ¡æ•°ï¼ˆåŒ…æ‹¬QUEUEDï¼‰
        self.running_tasks = 0    # å®é™…æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡æ•°ï¼ˆRUNNINGçŠ¶æ€ï¼‰
        self.lock = threading.Lock()
        
    def can_submit_task_conservative(self) -> bool:
        """
        ä¿å®ˆæ¨¡å¼ï¼šå…è®¸æœ€å¤š max_concurrent ä¸ªä»»åŠ¡å¹¶å‘è¿è¡Œ
        è¿™æ ·å¯ä»¥å……åˆ†åˆ©ç”¨RunningHubçš„å¹¶å‘èƒ½åŠ›åŒæ—¶é¿å…TASK_QUEUE_MAXEDé”™è¯¯
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä»…ç”¨äºæ£€æŸ¥ï¼Œä¸ä¿®æ”¹çŠ¶æ€
        """
        with self.lock:
            # ä½¿ç”¨å±€éƒ¨å˜é‡ç¡®ä¿å¤šçº¿ç¨‹ä¸€è‡´æ€§
            submitted = self.submitted_tasks
            running = self.running_tasks
            max_concurrent = self.max_concurrent
            
            # ğŸ”’ ä½¿ç”¨max_concurrentä½œä¸ºå¹¶å‘é™åˆ¶ï¼Œå…è®¸å¤šä¸ªä»»åŠ¡å¹¶å‘
            can_submit = submitted < max_concurrent
            
            if not can_submit:
                logger.info(f"ğŸš« å¹¶å‘æ§åˆ¶ï¼šå½“å‰å·²æäº¤ä»»åŠ¡æ•° {submitted} >= {max_concurrent}ï¼Œç­‰å¾…ä»»åŠ¡å®Œæˆ")
                logger.info(f"   å…¶ä¸­æ­£åœ¨è¿è¡Œ: {running}, æ’é˜Ÿä¸­: {submitted - running}")
            
            return can_submit
    
    def try_submit_task(self) -> bool:
        """
        ğŸ”’ åŸå­æ“ä½œï¼šæ£€æŸ¥å¹¶æäº¤ä»»åŠ¡ï¼ˆåœ¨åŒä¸€ä¸ªé”ä¸­å®Œæˆï¼‰
        è¿™æ ·å¯ä»¥é˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶é€šè¿‡æ£€æŸ¥å¹¶æäº¤ä»»åŠ¡çš„ç«äº‰æ¡ä»¶
        
        Returns:
            True: æˆåŠŸè·å¾—æäº¤æƒé™ï¼Œå·²å¢åŠ è®¡æ•°
            False: å½“å‰æ— æ³•æäº¤ï¼Œéœ€è¦ç­‰å¾…
        """
        with self.lock:
            # ä½¿ç”¨å±€éƒ¨å˜é‡ç¡®ä¿å¤šçº¿ç¨‹ä¸€è‡´æ€§
            submitted = self.submitted_tasks
            running = self.running_tasks
            max_concurrent = self.max_concurrent
            
            # ğŸ”’ åŸå­æ£€æŸ¥å’Œæäº¤ï¼šå…è®¸æœ€å¤š max_concurrent ä¸ªä»»åŠ¡å¹¶å‘
            can_submit = submitted < max_concurrent
            
            if can_submit:
                # ğŸ”’ å…³é”®ä¿®å¤ï¼šç«‹å³å¢åŠ å·²æäº¤å’Œè¿è¡Œä»»åŠ¡è®¡æ•°
                # è¿™æ ·å¯ä»¥é¿å…åœ¨è½®è¯¢è¿‡ç¨‹ä¸­çš„åŒæ­¥é—®é¢˜
                self.submitted_tasks += 1
                self.running_tasks += 1  # ç«‹å³è®¡ä¸ºè¿è¡Œä¸­ï¼Œä¸ç­‰å¾…è½®è¯¢ç¡®è®¤
                logger.info(f"âœ… è·å¾—ä»»åŠ¡æäº¤æƒé™ï¼Œå·²æäº¤: {self.submitted_tasks}/{max_concurrent}, è¿è¡Œä¸­: {self.running_tasks}")
                return True
            else:
                logger.info(f"ğŸš« æ— æ³•æäº¤ä»»åŠ¡ï¼šå½“å‰å·²æœ‰ {submitted}/{max_concurrent} ä¸ªä»»åŠ¡ (è¿è¡Œä¸­: {running}, æ’é˜Ÿä¸­: {submitted - running})")
                return False
    
    def task_finished(self):
        """è®°å½•ä»»åŠ¡å®Œæˆï¼ˆåŒ…æ‹¬æˆåŠŸå’Œå¤±è´¥ï¼‰"""
        with self.lock:
            self.submitted_tasks = max(0, self.submitted_tasks - 1)
            self.running_tasks = max(0, self.running_tasks - 1)
            # ä½¿ç”¨å±€éƒ¨å˜é‡ç¡®ä¿å¤šçº¿ç¨‹ä¸€è‡´æ€§
            running = self.running_tasks
            submitted = self.submitted_tasks
            max_concurrent = self.max_concurrent
            
            logger.info(f"ğŸ“Š ä»»åŠ¡å®Œæˆï¼Œå½“å‰è¿è¡Œä»»åŠ¡æ•°: {running}, å·²æäº¤ä»»åŠ¡æ•°: {submitted}/{max_concurrent}")
            
            # å½“å·²æäº¤ä»»åŠ¡æ•°å°äºmax_concurrentæ—¶ï¼Œå¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡
            if submitted < max_concurrent:
                logger.info(f"âœ… å¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡ (å½“å‰: {submitted}/{max_concurrent})")
    
    def task_failed_before_running(self):
        """è®°å½•ä»»åŠ¡åœ¨å¼€å§‹è¿è¡Œå‰å°±å¤±è´¥äº†ï¼ˆæäº¤å¤±è´¥æˆ–å¼‚å¸¸çŠ¶æ€ï¼‰"""
        with self.lock:
            self.submitted_tasks = max(0, self.submitted_tasks - 1)
            # ä½¿ç”¨å±€éƒ¨å˜é‡ç¡®ä¿å¤šçº¿ç¨‹ä¸€è‡´æ€§
            running = self.running_tasks
            submitted = self.submitted_tasks
            logger.info(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥ï¼Œå½“å‰è¿è¡Œä»»åŠ¡æ•°: {running}, å·²æäº¤ä»»åŠ¡æ•°: {submitted}")
    
    def get_submitted_count(self) -> int:
        """è·å–å½“å‰å·²æäº¤ä»»åŠ¡æ•°"""
        with self.lock:
            return self.submitted_tasks
    
    def get_running_count(self) -> int:
        """è·å–å½“å‰æ­£åœ¨è¿è¡Œä»»åŠ¡æ•°"""
        with self.lock:
            return self.running_tasks
    
    def get_status(self) -> dict:
        """è·å–å®Œæ•´çŠ¶æ€"""
        with self.lock:
            # ç¡®ä¿æ‰€æœ‰å˜é‡è®¿é—®éƒ½åœ¨é”ä¿æŠ¤ä¸‹ï¼Œä¿è¯å¤šçº¿ç¨‹ä¸€è‡´æ€§
            submitted = self.submitted_tasks
            running = self.running_tasks
            max_concurrent = self.max_concurrent
            conservative_threshold = self.conservative_threshold
            return {
                "submitted": submitted,
                "running": running,
                "queued": submitted - running,
                "max_concurrent": max_concurrent,
                "conservative_threshold": conservative_threshold
            }


# å…¨å±€å¹¶å‘ç®¡ç†å™¨ - ä½¿ç”¨æä¿å®ˆè®¾ç½®é¿å…TASK_QUEUE_MAXEDé”™è¯¯
_concurrency_manager = RunningHubConcurrencyManager(max_concurrent=3, conservative_threshold=1)


class JimengT2IRH:
    """RunningHub API Jimeng æ–‡æœ¬è½¬å›¾ç‰‡ç”Ÿæˆå™¨"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– JimengT2IRH
        
        Args:
            api_key: RunningHub API Keyï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        """
        self.api_key = api_key or RUNNINGHUB_API_CONFIG["api_key"]
        self.host = RUNNINGHUB_API_CONFIG["host"]
        self.base_url = RUNNINGHUB_API_CONFIG["base_url"]
        self.run_url = RUNNINGHUB_API_CONFIG["run_url"]
        # å°è¯•ä½¿ç”¨ä¸åŒçš„çŠ¶æ€æŸ¥è¯¢ç«¯ç‚¹ï¼Œå› ä¸ºå½“å‰ç«¯ç‚¹è¿”å›404
        self.status_url = "https://www.runninghub.cn/task/openapi/status"
        # åŒæ ·å°è¯•ä½¿ç”¨ä¸åŒçš„è¾“å‡ºæŸ¥è¯¢ç«¯ç‚¹
        self.outputs_url = "https://www.runninghub.cn/task/openapi/outputs"
        self.webapp_id = "1970112024036450306"
        self.output_node_id = "9" # Assuming same as flux, might need adjustment
        self.poll_interval = RUNNINGHUB_API_CONFIG["poll_interval"]
        
        self.headers = {
            'Host': self.host,
            'Content-Type': 'application/json'
        }
        
        logger.info(f"JimengT2IRH åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨WebApp ID: {self.webapp_id}")

    def generate_image(self,
                       prompt: str,
                       width: Optional[int] = None,
                       height: Optional[int] = None,
                       timeout: Optional[int] = None,
                       use_concurrency_control: bool = True,
                       on_start_callback: Optional[Callable[[], None]] = None) -> Optional[Dict[str, Any]]:
        """
        æ‰§è¡Œæ–‡æœ¬è½¬å›¾ç‰‡ç”Ÿæˆ.
        NOTE: width å’Œ height ç”¨äºå†³å®šæ¯”ä¾‹ï¼Œè€Œéç²¾ç¡®å°ºå¯¸ã€‚
        
        Args:
            prompt: æç¤ºè¯
            width: å›¾ç‰‡å®½åº¦, ç”¨äºåˆ¤æ–­æ¯”ä¾‹ (å¯é€‰)
            height: å›¾ç‰‡é«˜åº¦, ç”¨äºåˆ¤æ–­æ¯”ä¾‹ (å¯é€‰)
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
            use_concurrency_control: æ˜¯å¦ä½¿ç”¨å¹¶å‘æ§åˆ¶ï¼Œé»˜è®¤ä¸ºTrue
            on_start_callback: ä»»åŠ¡æˆåŠŸè·å–å¹¶å‘è®¸å¯åæ‰§è¡Œçš„å›è°ƒå‡½æ•°
            
        Returns:
            ç”Ÿæˆç»“æœå­—å…¸ï¼ŒåŒ…å«å›¾ç‰‡URLç­‰ä¿¡æ¯ï¼Œå¤±è´¥è¿”å›None
        """
        slot_acquired = False
        try:
            if use_concurrency_control:
                while not _concurrency_manager.try_submit_task():
                    status = _concurrency_manager.get_status()
                    logger.info(f"â³ å¹¶å‘æ§åˆ¶ï¼šå·²æäº¤ {status['submitted']}ï¼Œè¿è¡Œä¸­ {status['running']}ï¼Œæ’é˜Ÿä¸­ {status['queued']}ï¼Œç­‰å¾…ä»»åŠ¡å®Œæˆ...")
                    time.sleep(2)
                slot_acquired = True
            
            if on_start_callback:
                on_start_callback()

            # æ ¹æ®å®½é«˜æ¯”å†³å®šæ¯”ä¾‹é€‰æ‹© (é»˜è®¤ä¸º5ï¼Œå³ç«–å±)
            aspect_ratio_preset = "5" # Default to portrait
            if width is not None and height is not None:
                if width > height:
                    aspect_ratio_preset = "0" # Landscape
                elif width == height:
                    aspect_ratio_preset = "1" # Square, assuming 1 is square
                # else height > width, keep default "5"
            
            request_data = {
                "webappId": self.webapp_id,
                "apiKey": self.api_key,
                "nodeInfoList": [
                    {
                        "nodeId": "6",
                        "fieldName": "text",
                        "fieldValue": prompt,
                        "description": "è¾“å…¥æç¤ºè¯"
                    },
                    {
                        "nodeId": "31",
                        "fieldName": "value",
                        "fieldValue": aspect_ratio_preset,
                        "description": "æ¯”ä¾‹é€‰æ‹©"
                    }
                ]
            }
            
            # --- Submission loop with exponential backoff and jitter ---
            submission_result = None
            max_submission_retries = 3
            base_retry_delay = 5

            for attempt in range(max_submission_retries):
                response = requests.post(
                    url=self.run_url, 
                    headers=self.headers, 
                    data=json.dumps(request_data)
                )
                response.raise_for_status()
                submission_result = response.json()
                
                logger.info(f"=== ä»»åŠ¡æäº¤å°è¯• {attempt + 1}/{max_submission_retries} ç»“æœ ===")
                logger.info(f"å“åº”: {submission_result}")
                
                if submission_result.get('code') == 0:
                    break  # Success
                
                error_msg = submission_result.get('msg', 'æœªçŸ¥é”™è¯¯')
                if 'TASK_QUEUE_MAXED' in error_msg and attempt < max_submission_retries - 1:
                    retry_delay = base_retry_delay * (2 ** attempt) + random.uniform(0, 1)
                    logger.warning(f"âš ï¸ ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ (TASK_QUEUE_MAXED)ã€‚å°†åœ¨ {retry_delay:.2f} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    logger.error(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥: {error_msg}")
                    return None
            
            if not submission_result or submission_result.get('code') != 0:
                logger.error("âŒ ä»»åŠ¡æäº¤åœ¨æ‰€æœ‰é‡è¯•åä»ç„¶å¤±è´¥ã€‚")
                return None

            # --- Polling ---
            task_data = submission_result["data"]
            logger.info(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸ!")
            logger.info(f"å®Œæ•´ä»»åŠ¡æ•°æ®: {task_data}")
            
            # éªŒè¯ä»»åŠ¡æ•°æ®ç»“æ„
            if not task_data or not isinstance(task_data, dict):
                logger.error(f"âŒ ä»»åŠ¡æ•°æ®ç»“æ„å¼‚å¸¸: {task_data}")
                return None
                
            if "taskId" not in task_data:
                logger.error(f"âŒ ä»»åŠ¡æ•°æ®ä¸­ç¼ºå°‘taskIdå­—æ®µ: {task_data}")
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„ä»»åŠ¡IDå­—æ®µ
                possible_id_fields = ["id", "task_id", "taskid", "Id"]
                for field in possible_id_fields:
                    if field in task_data:
                        logger.info(f"ğŸ” å‘ç°å¯èƒ½çš„ä»»åŠ¡IDå­—æ®µ '{field}': {task_data[field]}")
                return None
            
            task_id = task_data["taskId"]
            logger.info(f"  ä»»åŠ¡ID: {task_id}")
            if "clientId" in task_data:
                logger.info(f"  å®¢æˆ·ç«¯ID: {task_data['clientId']}")
            if "taskStatus" in task_data:
                logger.info(f"  ä»»åŠ¡çŠ¶æ€: {task_data['taskStatus']}")
            logger.info("=" * 50)
            
            result = self._poll_task_status(task_id, timeout or RUNNINGHUB_API_CONFIG["generate_timeout"])
            return result
                
        except Exception as e:
            logger.error(f"å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return None
        finally:
            if slot_acquired:
                _concurrency_manager.task_finished()
    
    def _poll_task_status(self, task_id: str, timeout: int) -> Optional[Dict[str, Any]]:
        start_time = time.time()
        max_poll_retries = 3
        poll_retry_delay = 2

        while True:
            if (time.time() - start_time) > timeout:
                logger.error(f"ä»»åŠ¡ {task_id} è¶…æ—¶ ({timeout}ç§’)ï¼Œå·²é€€å‡ºè½®è¯¢")
                return None
            
            # --- Start of single polling attempt with retries ---
            poll_successful = False
            current_retries = max_poll_retries
            while current_retries > 0:
                try:
                    status_data = {"apiKey": self.api_key, "taskId": task_id}
                    response = requests.post(
                        url=self.status_url, 
                        headers=self.headers, 
                        data=json.dumps(status_data),
                        timeout=10 # Short timeout for status checks
                    )
                    response.raise_for_status()
                    status_result = response.json()
                    
                    logger.info(f"ğŸ”„ ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ (ä»»åŠ¡ID: {task_id}): {status_result}")

                    if status_result.get('code') == 0:
                        # å¤„ç†ä¸¤ç§å¯èƒ½çš„å“åº”æ ¼å¼ï¼š
                        # 1. dataæ˜¯å­—å…¸: {'data': {'taskStatus': 'RUNNING'}}
                        # 2. dataæ˜¯å­—ç¬¦ä¸²: {'data': 'RUNNING'}
                        task_data = status_result.get('data', {})
                        
                        if isinstance(task_data, str):
                            # dataç›´æ¥æ˜¯çŠ¶æ€å­—ç¬¦ä¸²
                            task_status = task_data
                        elif isinstance(task_data, dict):
                            # dataæ˜¯åŒ…å«taskStatusçš„å­—å…¸
                            task_status = task_data.get('taskStatus')
                        else:
                            # æœªçŸ¥æ ¼å¼
                            logger.warning(f"âš ï¸ æœªçŸ¥çš„ä»»åŠ¡æ•°æ®æ ¼å¼: {task_data}")
                            task_status = None

                        if task_status == 'SUCCESS':
                            logger.info(f"âœ… ä»»åŠ¡ {task_id} å®Œæˆï¼Œè·å–ç»“æœ...")
                            return self._get_task_outputs(task_id) # Final success state
                        elif task_status in ['FAIL', 'CANCEL']:
                            logger.error(f"âŒ ä»»åŠ¡ {task_id} å¤±è´¥æˆ–è¢«å–æ¶ˆ: {task_status}")
                            return None # Final fail state
                        elif task_status in ['QUEUED', 'RUNNING']:
                            # QUEUED, RUNNING, etc. This poll attempt was successful.
                            logger.info(f"â³ ä»»åŠ¡ {task_id} çŠ¶æ€: {task_status}ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡è½®è¯¢...")
                            poll_successful = True
                            break # Break the INNER retry loop
                        else:
                            logger.warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {task_status}")
                            poll_successful = True  # ä»ç„¶è®¤ä¸ºæŸ¥è¯¢æˆåŠŸï¼Œç»§ç»­è½®è¯¢
                            break
                    else:
                        # API returned a business error, treat as a transient poll failure
                        error_msg = status_result.get('msg', 'æœªçŸ¥APIé”™è¯¯')
                        raise Exception(f"APIè¿”å›ä¸šåŠ¡é”™è¯¯: code={status_result.get('code')}, msg={error_msg}")

                except Exception as e:
                    current_retries -= 1
                    logger.warning(f"âš ï¸ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€æ—¶é‡åˆ°é—®é¢˜: {e}ã€‚å‰©ä½™é‡è¯•æ¬¡æ•°: {current_retries}")
                    if current_retries > 0:
                        time.sleep(poll_retry_delay + random.uniform(0, 1))
            
            if not poll_successful:
                logger.error(f"âŒ ä»»åŠ¡ {task_id} çŠ¶æ€æŸ¥è¯¢åœ¨è¿ç»­ {max_poll_retries} æ¬¡å¤±è´¥åå½»åº•å¤±è´¥ã€‚")
                return None

            time.sleep(self.poll_interval)
    
    def _get_task_outputs(self, task_id: str) -> Optional[Dict[str, Any]]:
        try:
            outputs_data = {
                "apiKey": self.api_key,
                "taskId": task_id
            }
            
            response = requests.post(
                url=self.outputs_url,
                headers=self.headers,
                data=json.dumps(outputs_data)
            )
            response.raise_for_status()
            outputs_result = response.json()
            
            logger.info("=== ä»»åŠ¡è¾“å‡ºç»“æœ ===")
            logger.info(f"å“åº”: {outputs_result}")
            
            if outputs_result.get('code') != 0:
                logger.error(f"âŒ è·å–ä»»åŠ¡è¾“å‡ºå¤±è´¥: {outputs_result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return None
            
            data = outputs_result.get('data', [])
            if data:
                # Assuming the first output is the one we want.
                # A more robust solution would be to check node ID if available.
                for item in data:
                    if 'fileUrl' in item:
                         return {
                            'code': 0,
                            'data': {
                                'images': [{'imageUrl': item.get('fileUrl')}]
                            }
                        }
            
            logger.error("âŒ æœªè·å–åˆ°è¾“å‡ºç»“æœ")
            return None
                
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¾“å‡ºå¤±è´¥: {e}")
            return None

    def _download_image(self, image_url: str, output_path: str, retries: int = 3, delay: int = 5) -> Optional[str]:
        for attempt in range(retries):
            try:
                response = requests.get(image_url, timeout=60)
                response.raise_for_status()
                
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                
                logger.info(f"å›¾ç‰‡ä¸‹è½½å®Œæˆ: {output_path}")
                return output_path
                
            except requests.exceptions.RequestException as e:
                logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}")
                if attempt < retries - 1:
                    logger.info(f"å°†åœ¨ {delay} ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    logger.error("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¸‹è½½å¤±è´¥ã€‚")
                    return None
        return None

    def text_to_image(self, 
                      prompt: str,
                      output_path: str,
                      width: Optional[int] = None,
                      height: Optional[int] = None,
                      on_start_callback: Optional[Callable[[], None]] = None) -> Optional[str]:
        """
        ç”Ÿæˆå¹¶ä¸‹è½½å•å¼ å›¾ç‰‡
        """
        try:
            if os.path.exists(output_path):
                logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ: {output_path}")
                return output_path

            result = self.generate_image(
                prompt=prompt,
                width=width,
                height=height,
                on_start_callback=on_start_callback
            )
            
            if not result or result.get('code') != 0:
                logger.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å–åˆ°ç»“æœ")
                return None
            
            images = result.get('data', {}).get('images', [])
            if not images:
                logger.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å–åˆ°å›¾ç‰‡URL")
                return None
            
            image_url = images[0].get('imageUrl')
            if not image_url:
                logger.error("ç”Ÿæˆå¤±è´¥ï¼Œå›¾ç‰‡URLä¸ºç©º")
                return None

            output_dir = os.path.dirname(output_path)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
            
            return self._download_image(image_url, output_path)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {e}")
            return None

def create_jimeng_t2i_rh(api_key: Optional[str] = None) -> JimengT2IRH:
    return JimengT2IRH(api_key=api_key)


if __name__ == "__main__":
    generator = create_jimeng_t2i_rh()
    
    test_prompt = "æ²»æ„ˆç³»å¥¶æ²¹ç«¥è¯é£ï¼šé˜³å…‰æ¼«è¿›å¥¶æ²¹è‰²æœ¨å±‹ï¼Œçª—å¤–æ˜¯ç²‰ç™½æ¨±èŠ±æ—ï¼Œå±‹å†…æ¯›ç»’åœ°æ¯¯ä¸Šå †ç€è‰è“æŠ±æ•ï¼ŒçŒ«å’ªèœ·åœ¨é£˜ç€çƒ­æ°”çš„å§œé¥¼å±‹æ—ï¼Œç©ºæ°”æµ®ç€ç³–éœœå…‰æ–‘ï¼ŒæŸ”ç„¦å…‰å½±ï¼Œé©¬å¡é¾™é…è‰²ï¼Œç»†èŠ‚æ»¡æ˜¯è½¯ç³¯è‚Œç†"
    output_file = "jimeng_t2i_test.jpg"

    print(f"æ­£åœ¨ç”Ÿæˆå›¾ç‰‡ï¼Œæç¤ºè¯: {test_prompt}")
    
    saved_path = generator.text_to_image(
        prompt=test_prompt,
        output_path=output_file
    )
    
    if saved_path:
        print(f"å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œå·²ä¿å­˜è‡³: {saved_path}")
    else:
        print("å›¾ç‰‡ç”Ÿæˆå¤±è´¥ã€‚")
